pip install tensorflow opencv-python keras


git clone https://github.com/ondyari/FaceForensics.git


import cv2


def video_to_frames(video_path, output_folder):
    cap = cv2.VideoCapture(video_path)
    count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        cv2.imwrite(f"{output_folder}/frame{count}.jpg", frame)
        count += 1
    cap.release()


import cv2
import numpy as np


def preprocess_frame(frame, img_size=224):
    frame = cv2.resize(frame, (img_size, img_size))
    frame = frame / 255.0  # Normalize to [0, 1]
    return frame


from tensorflow.keras.applications import Xception
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model


base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(1, activation='sigmoid')(x)
model = Model(inputs=base_model.input, outputs=x)


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


from tensorflow.keras.preprocessing.image import ImageDataGenerator


train_datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)
train_gen = train_datagen.flow_from_directory('/content/FaceForensics', target_size=(224, 224), batch_size=32, class_mode='binary', subset='training')
val_gen = train_datagen.flow_from_directory('/content/FaceForensics', target_size=(224, 224), batch_size=32, class_mode='binary', subset='validation')


model.fit(train_gen, epochs=10, validation_data=val_gen)


loss, accuracy = model.evaluate(val_gen)
print(f"Validation Accuracy: {accuracy}")


model.save('deepfake_detection_model.h5')
